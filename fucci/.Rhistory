remove.packages("scDDboost")
library(roxygen2)
roxygenise("~/Desktop/scDDboost/")
install.packages("rjava")
install.packages("rJava")
library(rJava)
library(rJava)
library(rJava)
?rJava
??rJava
install.packages("rJava")
install.packages("rJava")
library(rJava)
dyn.load('/Library/Java/JavaVirtualMachines/jdk1.8.0_144.jdk/Contents/Home/jre/lib/server/libjvm.dylib')
require(rJava)
library("roxygen2")
roxygenise("~/Desktop/scDDboost/")
library(roxygen2)
roxygenise("~/Desktop/scDDboost_pkg/")
library("scDDboost")
K = 9
Posp = pat(K)[[1]]
ref9 = g_ref(Posp)
dim(ref9)
ref9[1,1]
ref9[1,2]
sum(ref[2,1])
sum(ref9[2,1])
sum(ref9[,2])
sum(ref9[,3])
sum(ref9[,4])
sum(ref9[,5])
sum(ref9[,1])
ref9[2,1]
ref9[2,2]
ref9[2,3]
ref9[2,4]
sum(ref9[2,])
ref[3,2]
ref9[3,2]
isref(Posp[3,],Posp[4,])
isref(Posp[3,],Posp[2,])
Posp[3,]
Posp[2,]
library("scDDboost")
K = 9
Posp = pat(K)[[1]]
ref9 = g_ref(Posp)
sum(ref9[,1])
sum(ref9[,2])
sum(ref9[,3])
library("scDDboost")
K = 9
Posp = pat(K)[[1]]
ref9 = g_ref(Posp)
sum(ref9[,2])
sum(ref9[,3])
sum(ref9[,1])
sum(ref9[,4])
sum(ref9[4,])
sum(ref9[5,])
sum(ref9[,8])
library("scDDboost")
K = 9
Posp = pat(K)[[1]]
ref9 = g_ref(Posp)
sum(ref9[,1])
sum(ref9[,2])
sum(ref9[,3])
ref[[3]]
data(ref)
K = 3
Posp = pat(K)[[1]]
ref[[3]]
g_ref(Posp)
g_ref
Posp[1,]
Posp
library(Rcpp)
Rcpp::Rcpp.package.skeleton()
library(nearN)
base = list()
base[[1]] = c(1,2,3)
base[[2]] = c(2,3,4)
base[[3]] = c(9,10,11)
rest = list()
rest[[1]] = c(11,12)
cls = c(1,1,2)
k = 1
ncl = 1
m = 1
n = 3
NN(base,cls,n,rest,m,k,ncl)
library(nearN)
base = list()
base[[1]] = c(1,2,3)
base[[2]] = c(2,3,4)
base[[3]] = c(9,10,11)
rest = list()
rest[[1]] = c(11,12)
cls = c(1,1,2)
NN(base,cls,3,rest,1,1,2)
cls = as.integer(cls)
NN(base,cls,3,rest,1,1,2)
NN(y, clus, 1000, y2, length(y2), 1, max(clus))
remove.packages(nearN)
remove.packages("nearN")
library(nearN)
base = list()
base[[1]] = c(1,2,3)
base[[2]] = c(2,3,4)
base[[3]] = c(9,10,11)
rest = list()
rest[[1]] = c(11,12)
cls = c(1,1,2)
cls = as.integer(cls)
NN(base,cls,3,rest,1,1,2)
library(anRpackage)
rcpp_hello_world()
dst()
library(nearN)
dst()
nearN::dst
library(nearN)
DST
DST()
library(scDDboost)
data("MultiGeneMat")
MultiSize=MedianNorm(MultiGeneMat)
Conditions=c("C1","C1","C2","C2","C3","C3")
PosParti=GetPatterns(Conditions)
MultiOut=EBMultiTest(MultiGeneMat,NgVector=NULL,Conditions=Conditions,
AllParti=PosParti, sizeFactors = MultiSize, maxround=5)
res = EBS(MultiGeneMat, c(1,1,2,2,3,3),1:500, MultiSize, iter = 10, rep(1,501), pat(3)[[1]])
res$r[1:10,1]
MultiSize
MultiOut$RList[[1]][1:10]
res = EBS(MultiGeneMat, c(1,1,2,2,3,3),1:500, rep(1,6), iter = 10, rep(1,501), pat(3)[[1]])
res$r[1:10,1]
MultiGeneMat[4,]
x = MultiGeneMat[4,]
y = x
y = y / MultiGeneMat
y
rm(y)
y = x
y = y / MultiSize
y
m1 = mean(y)
Data = MultiGeneMat
n1 = (y[1] + y[2]) / 2
n2 = (y[3] + y[4]) / 2
n3 = (y[5] + y[6]) / 2
(x[1] - n1)^2 + (x[2] - n1)^2
s1 = 52
s2 = (x[3] - n2)^2 + (x[4] - n2)^2
s2 = s2 /2
s2
s3 = (x[5] - n3)^2 + (x[6] - n3)^2
s3 = s3/2
s3
s1 + s2 + s3
6994.772 / 3
mean(y)
1441.456 / 2331.591
q = 0.618
q / (1 - q)
2331.591 * 1.61
s1 = (x[1] - n1)^2/MultiSize[1] + (x[2] - n1)^2/MultiSize[1]
s2 = (x[3] - n2)^2/MultiSize[3] + (x[4] - n2)^2/MultiSize[4]
s3 = (x[5] - n3)^2/MultiSize[5] + (x[6] - n3)^2/MultiSize[6]
s1 + s2 + s3
s1
s2
s3
(s1 + s2 + s3)/6
m1
v1 = (s1 + s2 + s3)/6
m1 = mean(y)
p = m1 / v1
r1 = m1 * p / (1 - p)
r1
p
tau=CI=CIthre=NULL
Dataraw=Data
DataNorm=GetNormalizedMat(Data, sizeFactors)
QuantileFor0=apply(DataNorm,1,function(i)quantile(i,Qtrm))
AllZeroNames=which(QuantileFor0<=QtrmCut)
NotAllZeroNames=which(QuantileFor0>QtrmCut)
Qtrm=1
QtrmCut=0
if(is.null(NgVector))NgVector=rep(1,nrow(Data))
NgVector=rep(1,nrow(Data))
IsoNamesIn=rownames(Data)
Names=paste("I",c(1:dim(Data)[1]),sep="")
names(IsoNamesIn)=Names
rownames(Data)=paste("I",c(1:dim(Data)[1]),sep="")
names(NgVector)=paste("I",c(1:dim(Data)[1]),sep="")
pool = F
NumCond=nlevels(Conditions)
CondLevels=levels(Conditions)
NoneZeroLength=nlevels(as.factor(NgVector))
NameList=sapply(1:NoneZeroLength,function(i)names(NgVector)[NgVector==i],simplify=F)
DataList=sapply(1:NoneZeroLength , function(i) Data[NameList[[i]],],simplify=F)
names(DataList)=names(NameList)
NumEachGroup=sapply(1:NoneZeroLength , function(i)dim(DataList)[i])
DataList.unlist=do.call(rbind, DataList)
sizeFactor
sizeFactors
sizeFactors = MultiSize
DataList.unlist.dvd=t(t( DataList.unlist)/sizeFactors)
DataListSP=vector("list",nlevels(Conditions))
DataListSP.dvd=vector("list",nlevels(Conditions))
SizeFSP=DataListSP
MeanSP=DataListSP
VarSP=DataListSP
GetPSP=DataListSP
RSP=DataListSP
CISP=DataListSP
tauSP=DataListSP
NumEachCondLevel=summary(Conditions)
CondLevelsUse=CondLevels[NumEachCondLevel>1]
NumCondUse=length(CondLevelsUse)
for (lv in 1:nlevels(Conditions)){
DataListSP[[lv]]= matrix(DataList.unlist[,Conditions==levels(Conditions)[lv]],nrow=dim(DataList.unlist)[1])
rownames(DataListSP[[lv]])=rownames(DataList.unlist)
DataListSP.dvd[[lv]]= matrix(DataList.unlist.dvd[,Conditions==levels(Conditions)[lv]],nrow=dim(DataList.unlist.dvd)[1])
if(ncol(DataListSP[[lv]])==1 & Pool==F & !is.null(CI)){
CISP[[lv]]=matrix(CI[,Conditions==levels(Conditions)[lv]],nrow=dim(DataList.unlist.dvd)[1])
tauSP[[lv]]=matrix(tau[,Conditions==levels(Conditions)[lv]],nrow=dim(DataList.unlist.dvd)[1])
}
# no matter sizeFactors is a vector or a matrix. Matrix should be columns are the normalization factors
# may input one for each
if(length(sizeFactors)==ncol(Data))SizeFSP[[lv]]=sizeFactors[Conditions==levels(Conditions)[lv]]
if(length(sizeFactors)==length(Data))SizeFSP[[lv]]=sizeFactors[,Conditions==levels(Conditions)[lv]]
MeanSP[[lv]]=rowMeans(DataListSP.dvd[[lv]])
names(MeanSP[[lv]])=rownames(DataListSP[[lv]])
if(length(sizeFactors)==ncol(Data))PrePareVar=sapply(1:ncol( DataListSP[[lv]]),function(i)( DataListSP[[lv]][,i]- SizeFSP[[lv]][i]*MeanSP[[lv]])^2 /SizeFSP[[lv]][i])
if(length(sizeFactors)==length(Data))PrePareVar=sapply(1:ncol( DataListSP[[lv]]),function(i)( DataListSP[[lv]][,i]- SizeFSP[[lv]][,i]*MeanSP[[lv]])^2 /SizeFSP[[lv]][,i])
if(ncol(DataListSP[[lv]])==1 & Pool==F & !is.null(CI))
VarSP[[lv]]=as.vector(((DataListSP[[lv]]/tauSP[[lv]]) * CISP[[lv]]/(CIthre*2))^2)
if( Pool==T){
VarSP[[lv]]=VarPool
}
if(ncol(DataListSP[[lv]])!=1){
VarSP[[lv]]=rowSums(PrePareVar)/ncol( DataListSP[[lv]])
names(VarSP[[lv]])=rownames(DataList.unlist)
GetPSP[[lv]]=MeanSP[[lv]]/VarSP[[lv]]
RSP[[lv]]=MeanSP[[lv]]*GetPSP[[lv]]/(1-GetPSP[[lv]])
}
names(MeanSP[[lv]])=rownames(DataList.unlist)
}
Pool = F
for (lv in 1:nlevels(Conditions)){
DataListSP[[lv]]= matrix(DataList.unlist[,Conditions==levels(Conditions)[lv]],nrow=dim(DataList.unlist)[1])
rownames(DataListSP[[lv]])=rownames(DataList.unlist)
DataListSP.dvd[[lv]]= matrix(DataList.unlist.dvd[,Conditions==levels(Conditions)[lv]],nrow=dim(DataList.unlist.dvd)[1])
if(ncol(DataListSP[[lv]])==1 & Pool==F & !is.null(CI)){
CISP[[lv]]=matrix(CI[,Conditions==levels(Conditions)[lv]],nrow=dim(DataList.unlist.dvd)[1])
tauSP[[lv]]=matrix(tau[,Conditions==levels(Conditions)[lv]],nrow=dim(DataList.unlist.dvd)[1])
}
# no matter sizeFactors is a vector or a matrix. Matrix should be columns are the normalization factors
# may input one for each
if(length(sizeFactors)==ncol(Data))SizeFSP[[lv]]=sizeFactors[Conditions==levels(Conditions)[lv]]
if(length(sizeFactors)==length(Data))SizeFSP[[lv]]=sizeFactors[,Conditions==levels(Conditions)[lv]]
MeanSP[[lv]]=rowMeans(DataListSP.dvd[[lv]])
names(MeanSP[[lv]])=rownames(DataListSP[[lv]])
if(length(sizeFactors)==ncol(Data))PrePareVar=sapply(1:ncol( DataListSP[[lv]]),function(i)( DataListSP[[lv]][,i]- SizeFSP[[lv]][i]*MeanSP[[lv]])^2 /SizeFSP[[lv]][i])
if(length(sizeFactors)==length(Data))PrePareVar=sapply(1:ncol( DataListSP[[lv]]),function(i)( DataListSP[[lv]][,i]- SizeFSP[[lv]][,i]*MeanSP[[lv]])^2 /SizeFSP[[lv]][,i])
if(ncol(DataListSP[[lv]])==1 & Pool==F & !is.null(CI))
VarSP[[lv]]=as.vector(((DataListSP[[lv]]/tauSP[[lv]]) * CISP[[lv]]/(CIthre*2))^2)
if( Pool==T){
VarSP[[lv]]=VarPool
}
if(ncol(DataListSP[[lv]])!=1){
VarSP[[lv]]=rowSums(PrePareVar)/ncol( DataListSP[[lv]])
names(VarSP[[lv]])=rownames(DataList.unlist)
GetPSP[[lv]]=MeanSP[[lv]]/VarSP[[lv]]
RSP[[lv]]=MeanSP[[lv]]*GetPSP[[lv]]/(1-GetPSP[[lv]])
}
names(MeanSP[[lv]])=rownames(DataList.unlist)
}
lv
DataListSP=vector("list",nlevels(Conditions))
DataListSP.dvd=vector("list",nlevels(Conditions))
SizeFSP=DataListSP
MeanSP=DataListSP
VarSP=DataListSP
GetPSP=DataListSP
RSP=DataListSP
CISP=DataListSP
tauSP=DataListSP
nlevels(Conditions)
Conditions = as.factor(Conditions)
DataListSP=vector("list",nlevels(Conditions))
DataListSP.dvd=vector("list",nlevels(Conditions))
SizeFSP=DataListSP
MeanSP=DataListSP
VarSP=DataListSP
GetPSP=DataListSP
RSP=DataListSP
CISP=DataListSP
tauSP=DataListSP
NumEachCondLevel=summary(Conditions)
CondLevelsUse=CondLevels[NumEachCondLevel>1]
NumCondUse=length(CondLevelsUse)
for (lv in 1:nlevels(Conditions)){
DataListSP[[lv]]= matrix(DataList.unlist[,Conditions==levels(Conditions)[lv]],nrow=dim(DataList.unlist)[1])
rownames(DataListSP[[lv]])=rownames(DataList.unlist)
DataListSP.dvd[[lv]]= matrix(DataList.unlist.dvd[,Conditions==levels(Conditions)[lv]],nrow=dim(DataList.unlist.dvd)[1])
if(ncol(DataListSP[[lv]])==1 & Pool==F & !is.null(CI)){
CISP[[lv]]=matrix(CI[,Conditions==levels(Conditions)[lv]],nrow=dim(DataList.unlist.dvd)[1])
tauSP[[lv]]=matrix(tau[,Conditions==levels(Conditions)[lv]],nrow=dim(DataList.unlist.dvd)[1])
}
# no matter sizeFactors is a vector or a matrix. Matrix should be columns are the normalization factors
# may input one for each
if(length(sizeFactors)==ncol(Data))SizeFSP[[lv]]=sizeFactors[Conditions==levels(Conditions)[lv]]
if(length(sizeFactors)==length(Data))SizeFSP[[lv]]=sizeFactors[,Conditions==levels(Conditions)[lv]]
MeanSP[[lv]]=rowMeans(DataListSP.dvd[[lv]])
names(MeanSP[[lv]])=rownames(DataListSP[[lv]])
if(length(sizeFactors)==ncol(Data))PrePareVar=sapply(1:ncol( DataListSP[[lv]]),function(i)( DataListSP[[lv]][,i]- SizeFSP[[lv]][i]*MeanSP[[lv]])^2 /SizeFSP[[lv]][i])
if(length(sizeFactors)==length(Data))PrePareVar=sapply(1:ncol( DataListSP[[lv]]),function(i)( DataListSP[[lv]][,i]- SizeFSP[[lv]][,i]*MeanSP[[lv]])^2 /SizeFSP[[lv]][,i])
if(ncol(DataListSP[[lv]])==1 & Pool==F & !is.null(CI))
VarSP[[lv]]=as.vector(((DataListSP[[lv]]/tauSP[[lv]]) * CISP[[lv]]/(CIthre*2))^2)
if( Pool==T){
VarSP[[lv]]=VarPool
}
if(ncol(DataListSP[[lv]])!=1){
VarSP[[lv]]=rowSums(PrePareVar)/ncol( DataListSP[[lv]])
names(VarSP[[lv]])=rownames(DataList.unlist)
GetPSP[[lv]]=MeanSP[[lv]]/VarSP[[lv]]
RSP[[lv]]=MeanSP[[lv]]*GetPSP[[lv]]/(1-GetPSP[[lv]])
}
names(MeanSP[[lv]])=rownames(DataList.unlist)
}
MeanList=rowMeans(DataList.unlist.dvd)
VarList=apply(DataList.unlist.dvd, 1, var)
MeanList[[4]]
m1
Varcbind=do.call(cbind,VarSP[CondLevels%in%CondLevelsUse])
PoolVarSpeedUp_MDFPoi_NoNormVarList=rowMeans(Varcbind)
VarrowMin=apply(Varcbind,1,min)
Varcbind
NumCond=nlevels(Conditions)
CondLevels=levels(Conditions)
Varcbind=do.call(cbind,VarSP[CondLevels%in%CondLevelsUse])
PoolVarSpeedUp_MDFPoi_NoNormVarList=rowMeans(Varcbind)
VarrowMin=apply(Varcbind,1,min)
NumCond=nlevels(Conditions)
CondLevels=levels(Conditions)
CondLevels
CondLevelsUse
NumEachCondLevel=summary(Conditions)
NumEachCondLevel
CondLevelsUse=CondLevels[NumEachCondLevel>1]
NumCondUse=length(CondLevelsUse)
Varcbind=do.call(cbind,VarSP[CondLevels%in%CondLevelsUse])
PoolVarSpeedUp_MDFPoi_NoNormVarList=rowMeans(Varcbind)
VarrowMin=apply(Varcbind,1,min)
GetP=MeanList/PoolVarSpeedUp_MDFPoi_NoNormVarList
EmpiricalRList=MeanList*GetP/(1-GetP)
EmpiricalRList[4]
GetP[4]
MeanList[4]
PoolVarSpeedUp_MDFPoi_NoNormVarList[4]
Varcbind[4]
Varcbind[[4]]
dim(Varcbind)
Varcbind[4,]
x
y
n1
s1
s1 = (x[1] - n1)^2/MultiSize[1] + (x[2] - n1)^2/MultiSize[1]
s1
s2
s3
n3
(x[5] - n3)^2
(x[6] - n3)
PrePareVar[4]
PrePareVar[4,]
SizeFSP[[lv]][1]
SizeFSP[[lv]]
MultiSize
i
DataListSP[[lv]][4,1]- SizeFSP[[lv]][1]*MeanSP[[lv]][4])^2 /SizeFSP[[lv]][1]
DataListSP[[lv]][4,1]
SizeFSP[[lv]][1]
MeanSP[[lv]][4]
n3
(DataListSP[[lv]][,i]- SizeFSP[[lv]][i]*MeanSP[[lv]])^2
(DataListSP[[lv]][4,1]- SizeFSP[[lv]][1]*MeanSP[[lv]][4])^2 /SizeFSP[[lv]][1]
(x[5] - n3)^2/MultiSize[5]
ls()
library(DPpackage)  ## for MCMC
set.seed(75751)
# a toy data set
mu <- 2*c( rep(-3,15), rep(-1,20), rep(0,20), rep(1,30), rep(5,15) )
sig <- 1
true.clust <- match(mu, unique(mu))
n <- length(mu)
y <- rnorm(n,mean=mu, sd=sig)
f <- as.factor(1:n)
# try DPlmm
#prior <- list( alpha=1, nu0=1, tau1=1, tau2=1, tinv=diag(1), mub=0, Sb=diag(1) )
prior <- list( alpha=1, nu0=1, tau1=0.1, tau2=0.1, tinv=diag(1), mub=0, Sb=diag(1) )
nburn <-50
nsave <- 1e3
nskip <-100
ndisplay <-100
mcmc <- list(nburn=nburn,nsave=nsave,nskip=nskip,ndisplay=ndisplay)
state <- NULL
fit <- DPlmm( fixed=y~1, random=~1|f, mcmc=mcmc, state=state, status=TRUE, prior=prior )
# let me extract pairwise posterior co-cluster probability from saved stateo
u <- fit$save.state$randsave[,-(n+1)]
ok <- fit$save.state$thetasave[,5] == 5  ### 5 clusters
u <- fit$save.state$randsave[ok,-(n+1)]
B <- sum(ok)
bayes.clust <- matrix(NA, B, n)
for( b in 1:B )
{
tmp <- u[b,]
bayes.clust[b,] <- match( tmp, unique(tmp) )
}
ABayes <- matrix(0, n,n )
for( i in 1:B )
{
tmp <- outer( u[i,], u[i,], "==" )
ABayes <- ABayes + tmp/B
}
image(ABayes)
## so that seems to work; now try randomized clustering with Gamma(1/2,1) weights
## and maybe some distance shrinkage adjustment
#e.g
library(cluster)
dst <- dist(y)
dst.m <- as.matrix(dst)
ii <- 1:n
ok <- outer(ii,ii,">")
dst.vec <- dst.m[ok]
dst.vec
dim(dst.vec)
len(y)
length(y)
nloglik <- function(theta, x )
{
a <- theta[1] # shape for prior
b <- theta[2] # rate for prior
alpha <- theta[3] # shape for sampling model
m <- length(x)
## make sure a > 0, b > 0 , alpha, and x all >=0, at least one >
pp <- b/(b+x)
ll  <- m * ( lgamma(a+alpha) - lgamma(a) -lgamma(alpha) ) + a*sum( log(pp) ) +
alpha * sum( log(1-pp) ) - sum( log(x) )
return( -ll  )
}
fit2 <- nlminb( start=c(5,10,5), objective=nloglik, x=dst.vec, lower=c(0,0,0) )
print( c(fit2$convergence, fit2$par) )
hyps <- fit2$par
del <- 1/rgamma( 10000, shape=10, rate= 1 )
dd <- rgamma( 10000, shape=10, rate=(1/del) )
fit3 <- nlminb( start=c(1,5,10), objective=nloglik, x=dd, lower=c(0,0,0) )
del
fit3
fit3 <- nlminb( start=c(1,5,10), objective=nloglik, x=dd, lower=c(0,0,0) )
fit3
fit2
hist(dst.m
)
hist(dst.vec
)
hist(dd)
hist(dst.vec
)
len(ok)
length(ok)
ok[1:10]
#using FUCCI data
load("sctrim.RData")
setwd("~/Desktop/scDDboost_paper/scDDboost/fucci/")
d
#using FUCCI data
load("sctrim.RData")
library(SC3)
X <- SingleCellExperiment(assays = list(normcounts = edat), colData = colnames(edat))
dim(edat)
normcounts
X <- SingleCellExperiment(assays = list(normcounts = edat), colData = colnames(edat))
X <- SingleCellExperiment(assays = list(normcounts = edat[[1]]), colData = colnames(edat))
edat[[1]]
is.matrix(edat[[1]])
dim(edat[[1]])
data_count = as.matrix(edat)
X <- SingleCellExperiment(assays = list(normcounts = edat[[1]]), colData = colnames(edat))
colnames(edat)
X <- SingleCellExperiment(assays = list(normcounts = edat), colData = colnames(edat))
X <- SingleCellExperiment(assays = list(normcounts = data_count), colData = colnames(edat))
counts(X) <- normcounts(X)
logcounts(X) <- log2(normcounts(X) + 1)
?sc3_calc_consens
consen.D = sc3_calc_consens(X)
pre_output = sc3_kmeans(X)
tran.D = sc3_calc_transfs(X)
dst.sc3 = sc3_calc_dists(X)
?sc3_calc_dists
source("https://bioconductor.org/biocLite.R")
biocLite("SC3")
library(SC3)
dst.sc3 = sc3_calc_dists(X)
?sc3_calc_dists
?sc3_calc_dists
