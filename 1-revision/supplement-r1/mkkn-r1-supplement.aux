\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ref:Leng}
\citation{ref:Leng}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}R package}{2}{subsection.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Modeling}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data Structure, Sampling Model, and Parameters}{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Method Structure and Clustering}{2}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}EBSeq}{2}{subsubsection.2.2.1}}
\citation{ref:dahl}
\citation{ref:dahl}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}modalClust}{4}{subsubsection.2.2.2}}
\citation{JSSv040i05}
\citation{selK}
\citation{selK}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Randomized $K-$means}{6}{subsubsection.2.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Selecting $K$}{6}{subsubsection.2.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {S1}{\ignorespaces  Adjusted RAND index of clusterings generated by randomizing distances. We investigate the variation of clustering given by random weighting through 8 datasets and each dataset we are using 100 random distances. \relax }}{7}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:ARI}{{S1}{7}{Adjusted RAND index of clusterings generated by randomizing distances. We investigate the variation of clustering given by random weighting through 8 datasets and each dataset we are using 100 random distances. \relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Likelihood ratio test for common shape parameter}{7}{subsection.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {S2}{\ignorespaces Comparison between random weighting scheme and Dirichlet-process procedure. Top: heatmap of probabilities that two elements belong to the same class given the whole data. Bottom: scatterplot of these posterior probabilities (left), and adjusted RAND index comparing to the underlying true class label (right).\relax }}{8}{figure.caption.2}}
\newlabel{fig:simu}{{S2}{8}{Comparison between random weighting scheme and Dirichlet-process procedure. Top: heatmap of probabilities that two elements belong to the same class given the whole data. Bottom: scatterplot of these posterior probabilities (left), and adjusted RAND index comparing to the underlying true class label (right).\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Negative binomial fitting}{8}{subsection.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {S3}{\ignorespaces cumulative distribution for p values of LRT\relax }}{9}{figure.caption.3}}
\newlabel{fig:lrt}{{S3}{9}{cumulative distribution for p values of LRT\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Double Dirichlet Mixture}{9}{subsection.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {S4}{\ignorespaces violin plot of the 57 genes having evidence against negative binomial distribution assumption and uniquely called positive under \texttt  {scDDboost}\relax }}{10}{figure.caption.4}}
\newlabel{fig:s11}{{S4}{10}{violin plot of the 57 genes having evidence against negative binomial distribution assumption and uniquely called positive under \texttt {scDDboost}\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Numerical Experiments}{13}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Synthetic Data}{13}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {S5}{\ignorespaces First two principal components of transcripts under different parameters for simulated data. Horizontal axis refers to first component, vertical axis refers to second component. Different parameters resulted in different degree of separation of subtypes. We have 4 different settings for hyper-parameters of simulation, each setting has 10 replicates. From left to right, the associated hyper-parameters are (0.1,0.4), (-0.1,0.3), (0.3,0.5), (-0.1,1). Here we have 3 subtypes\relax }}{13}{figure.caption.5}}
\newlabel{fig:pca1}{{S5}{13}{First two principal components of transcripts under different parameters for simulated data. Horizontal axis refers to first component, vertical axis refers to second component. Different parameters resulted in different degree of separation of subtypes. We have 4 different settings for hyper-parameters of simulation, each setting has 10 replicates. From left to right, the associated hyper-parameters are (0.1,0.4), (-0.1,0.3), (0.3,0.5), (-0.1,1). Here we have 3 subtypes\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S6}{\ignorespaces Similar plots as Supplementary Figure\nobreakspace  {}\ref  {fig:pca1}, but for 7 subtypes\relax }}{14}{figure.caption.6}}
\newlabel{fig:pca2}{{S6}{14}{Similar plots as Supplementary Figure~\ref {fig:pca1}, but for 7 subtypes\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S7}{\ignorespaces Similar plots as Sumpplementary Figure\nobreakspace  {}\ref  {fig:pca1}, but for 12 subtypes\relax }}{14}{figure.caption.7}}
\newlabel{fig:pca3}{{S7}{14}{Similar plots as Sumpplementary Figure~\ref {fig:pca1}, but for 12 subtypes\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S8}{\ignorespaces $P(ED_g|X,y)$ given by scDDboost (horizontal) versus empirical Wasserstein distance (vertical). Genes associated with boxes from left to right having $P(ED_g|X,y)$ range from 0 - 0.2, 0.2 - 0.4, 0.4 - 0.6, 0.6 - 0.8, 0.8 - 1. For simulation cases with parameters in the format: number of clusters / shape / scale\relax }}{15}{figure.caption.8}}
\newlabel{fig:simu_wad}{{S8}{15}{$P(ED_g|X,y)$ given by scDDboost (horizontal) versus empirical Wasserstein distance (vertical). Genes associated with boxes from left to right having $P(ED_g|X,y)$ range from 0 - 0.2, 0.2 - 0.4, 0.4 - 0.6, 0.6 - 0.8, 0.8 - 1. For simulation cases with parameters in the format: number of clusters / shape / scale\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S9}{\ignorespaces Roc curve of the 12 simulation settings, under each setting, TPR and FPR are averaged over ten replicates, generally \texttt  {scDDboost} performs better than other methods\relax }}{16}{figure.caption.9}}
\newlabel{fig:roc}{{S9}{16}{Roc curve of the 12 simulation settings, under each setting, TPR and FPR are averaged over ten replicates, generally \texttt {scDDboost} performs better than other methods\relax }{figure.caption.9}{}}
\citation{oscope}
\citation{Lane}
\citation{Shalek}
\citation{Trapnell}
\citation{Engel}
\citation{EMTAB}
\citation{Tasic}
\citation{oscope}
\citation{sc3}
\citation{Deng193}
\citation{Guo}
\citation{chu}
\citation{Darmanis}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Empirical Study}{17}{subsection.3.2}}
\@writefile{lot}{\contentsline {table}{\numberline {S1}{\ignorespaces Datasets used for empirical study\relax }}{17}{table.caption.10}}
\newlabel{table:1}{{S1}{17}{Datasets used for empirical study\relax }{table.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S10}{\ignorespaces $P(ED_g|X,y)$ given by scDDboost versus empirical Wasserstein distance. Genes associated with boxes from left to right having $P(ED_g|X,y)$ range from 0 - 0.2, 0.2 - 0.4, 0.4 - 0.6, 0.6 - 0.8, 0.8 - 1, data used: FUCCI\relax }}{18}{figure.caption.11}}
\newlabel{fig:wad}{{S10}{18}{$P(ED_g|X,y)$ given by scDDboost versus empirical Wasserstein distance. Genes associated with boxes from left to right having $P(ED_g|X,y)$ range from 0 - 0.2, 0.2 - 0.4, 0.4 - 0.6, 0.6 - 0.8, 0.8 - 1, data used: FUCCI\relax }{figure.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S2}{\ignorespaces Datasets used for null cases, as cells are coming from same biological condition, there should not be any differential distributed genes, any positive call is false positive\relax }}{18}{table.caption.12}}
\newlabel{table:2}{{S2}{18}{Datasets used for null cases, as cells are coming from same biological condition, there should not be any differential distributed genes, any positive call is false positive\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Robustness}{19}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {S11}{\ignorespaces PDD change under different number of subtypes $K$ for dataset DEC-EC (GSE75748). We select $K = 4$, which also stabilize the PDD.\relax }}{19}{figure.caption.13}}
\newlabel{fig:rwk}{{S11}{19}{PDD change under different number of subtypes $K$ for dataset DEC-EC (GSE75748). We select $K = 4$, which also stabilize the PDD.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S12}{\ignorespaces PDD under $K = 5$ vs. $K = 6$ for dataset DEC-EC (GSE75748). PDD without randomization (left) vs. PDD with randomization (right). \texttt  {scDDboost} gained robustness through random weighting.\relax }}{20}{figure.caption.14}}
\newlabel{fig:s10}{{S12}{20}{PDD under $K = 5$ vs. $K = 6$ for dataset DEC-EC (GSE75748). PDD without randomization (left) vs. PDD with randomization (right). \texttt {scDDboost} gained robustness through random weighting.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S13}{\ignorespaces Under NULL case, using dataset EMTAB2805, when using too big $K$ we may lose FDR control (black dashed line shows proportion of false positive identified by scDDboost under 0.05 threshold, while validity score stabilized after $K > 2$ \relax }}{20}{figure.caption.15}}
\newlabel{fig:lfdr}{{S13}{20}{Under NULL case, using dataset EMTAB2805, when using too big $K$ we may lose FDR control (black dashed line shows proportion of false positive identified by scDDboost under 0.05 threshold, while validity score stabilized after $K > 2$ \relax }{figure.caption.15}{}}
\citation{ineq}
\@writefile{toc}{\contentsline {section}{\numberline {4}Posterior consistency}{21}{section.4}}
\bibstyle{imsart-nameyear}
\bibdata{./supp_references/wlr_ref}
\@writefile{lof}{\contentsline {figure}{\numberline {S14}{\ignorespaces Four subtypes of cells, simplexes of $(\phi ,\psi )$ satisfying different constraints.\relax }}{23}{figure.caption.16}}
\newlabel{fig:issue}{{S14}{23}{Four subtypes of cells, simplexes of $(\phi ,\psi )$ satisfying different constraints.\relax }{figure.caption.16}{}}
\bibcite{EMTAB}{{1}{2015}{{Buettner et~al.}}{{}}}
\bibcite{chu}{{2}{2016}{{Chu et~al.}}{{}}}
\bibcite{ref:dahl}{{3}{2009}{{Dahl}}{{}}}
\bibcite{Darmanis}{{4}{2017}{{Darmanis et~al.}}{{}}}
\bibcite{Deng193}{{5}{2014}{{Deng et~al.}}{{}}}
\bibcite{Engel}{{6}{2016}{{Engel et~al.}}{{}}}
\bibcite{Guo}{{7}{2015}{{Guo et~al.}}{{}}}
\bibcite{JSSv040i05}{{8}{2011}{{Jara et~al.}}{{}}}
\bibcite{sc3}{{9}{2017}{{Kiselev et~al.}}{{}}}
\bibcite{Lane}{{10}{2017}{{Lane et~al.}}{{}}}
\bibcite{ref:Leng}{{11}{2013}{{Leng et~al.}}{{}}}
\bibcite{oscope}{{12}{2015}{{Leng et~al.}}{{}}}
\bibcite{ineq}{{13}{2007}{{Li and ping Chen}}{{}}}
\bibcite{selK}{{14}{2000}{{Ray and Turi}}{{}}}
\bibcite{Shalek}{{15}{2014}{{Shalek et~al.}}{{}}}
\bibcite{Tasic}{{16}{2016}{{Tasic et~al.}}{{}}}
\bibcite{Trapnell}{{17}{2014}{{Trapnell et~al.}}{{}}}
\@writefile{toc}{\contentsline {section}{References}{24}{section*.18}}
